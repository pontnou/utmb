{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lectura y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Lectura de ficheros csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Se hace una primera inspección de los ficheros descargados, sin leerlos, y se comprueba que hay 15 ficheros csv que van del año 2003 al 2017. El correspondiente al año 2003 es particularmente pequeño comparado con los otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is os\n",
      " Volume Serial Number is 48F1-458F\n",
      "\n",
      " Directory of c:\\Users\\David\\OneDrive\\uah\\03_ead\\Python\\pecP\\raw\n",
      "\n",
      "08/31/2018  09:41 AM             4,323 utmb_2003.csv\n",
      "08/31/2018  09:41 AM           201,568 utmb_2004.csv\n",
      "08/31/2018  09:41 AM           379,090 utmb_2005.csv\n",
      "08/31/2018  09:41 AM           543,503 utmb_2006.csv\n",
      "08/31/2018  09:41 AM           486,606 utmb_2007.csv\n",
      "08/31/2018  09:41 AM           531,808 utmb_2008.csv\n",
      "08/31/2018  09:41 AM           523,047 utmb_2009.csv\n",
      "08/31/2018  09:41 AM           210,565 utmb_2010.csv\n",
      "08/31/2018  09:41 AM           510,921 utmb_2011.csv\n",
      "08/31/2018  09:41 AM           383,876 utmb_2012.csv\n",
      "08/31/2018  09:41 AM           599,283 utmb_2013.csv\n",
      "08/31/2018  09:41 AM           576,243 utmb_2014.csv\n",
      "08/31/2018  09:41 AM           624,196 utmb_2015.csv\n",
      "08/31/2018  09:41 AM           606,449 utmb_2016.csv\n",
      "08/31/2018  09:41 AM           615,921 utmb_2017.csv\n",
      "              15 File(s)      6,797,399 bytes\n",
      "               0 Dir(s)  57,563,144,192 bytes free\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('dir raw\\\\utmb*.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Para poder cargar cada fichero como un dataframe sin tener que definir explícitamente una variable para cada uno de ellos, los almacenaré en un diccionario cuya clave será el año del fichero y el valor, el dataframe correspondiente. Igualmente, se guardarán en un único dataframe todos los dataframe anuales concatenados, así se podrán inspeccionar todos los datos juntos. A cada dataframe se le añade una variable con el año correspondiente. Declaro una función auxiliar para poder leer los ficheros ya que será reutilizada más adelante. Para esta parte del trabajo será suficiente leer solo un par de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '.\\\\'\n",
    "raw_folder = 'raw'\n",
    "files = os.listdir(root + raw_folder)\n",
    "\n",
    "\n",
    "def full_file(folder, file):\n",
    "    return root + folder + '/' + file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Year']\n",
      "2004 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Voza', 'Conta', 'Bonhom', 'Chap', 'Seigne', 'Favre', 'Courm', 'Bertone', 'Elena', 'ColFerr', 'Fouly', 'Champ', 'Bovine', 'Trient', 'Vallorc', 'Gardes', 'Cham', 'Year']\n",
      "2005 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Col de Voza', 'Les Contamines', 'La Balme', 'Les Chapieux CCAS', 'Col de la Seigne', 'Refuge Elisabetta', 'Arête Mont-Favre', 'Col Chécrouit - Maison Vieille', 'Courmayeur - Dolonne', 'Refuge Bertone', 'Refuge Bonatti', 'Arnuva', 'Grand Col Ferret', 'La Peulaz', 'La Fouly', 'Praz de Fort', \"Champex d'en Bas\", 'Bovine', 'Trient', 'Les Tseppes', 'Vallorcine', 'Argentière', 'Chamonix - Arrivée', 'Year']\n",
      "2006 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Col de Voza', 'Les Contamines', 'La Balme', 'Refuge Croix du Bonhomme', 'Les Chapieux CCAS', 'Col de la Seigne', 'Refuge Elisabetta', 'Arête Mont-Favre', 'Col Chécrouit - Maison Vieille', 'Courmayeur - Dolonne', 'Refuge Bertone', 'Refuge Bonatti', 'Arnuva', 'Grand Col Ferret', 'La Peulaz', 'La Fouly', 'Praz de Fort', 'Champex Lac', 'Bovine', 'Trient', 'Les Tseppes', 'Vallorcine', 'Argentière', 'Chamonix - Arrivée', 'Year']\n",
      "2007 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'La Charme', 'Saint-Gervais', 'Les Contamines', 'La Balme', 'Refuge Croix du Bonhomme', 'Les Chapieux CCAS', 'Col de la Seigne', 'Refuge Elisabetta', 'Col Chécrouit - Maison Vieille', 'Courmayeur - Dolonne', 'Refuge Bertone', 'Refuge Bonatti', 'Arnuva', 'Grand Col Ferret', 'La Fouly', 'Champex Lac', 'Bovine', 'Trient', 'Catogne', 'Vallorcine', 'Argentière', 'Chamonix - Arrivée', 'Year']\n",
      "2008 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Charme', 'StGer', 'Conta', 'Balme', 'Bonhom', 'Chap', 'Seigne', 'Combal', 'MtFavre', 'Checr', 'Courm', 'Berton', 'Bonatti', 'Arnuva', 'Ferret', 'Fouly', 'Champ', 'Bovine', 'Trient', 'Catogn', 'Vallor', 'TeteVnt', 'Fleg', 'Cham', 'Year']\n",
      "2009 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'stGer', 'conta', 'balme', 'crxBon', 'chap', 'seign', 'combal', 'mtFav', 'checr', 'courm', 'bert', 'bonat', 'arnuv', 'ferret', 'fouly', 'champ', 'bovine', 'trient', 'catog', 'vallo', 'teteVnt', 'fleg', 'cham', 'Year']\n",
      "2010 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delevre', 'st Ger', 'Conta', 'Balme', 'Bonhom', 'Chapieu', 'Seigne', 'Combal', 'M Favre', 'Checrou', 'Courm', 'Bertone', 'Bonatti', 'Arnuva', 'Ferret', 'Fouly', 'Champex', 'Bovine', 'Trient', 'Catogne', 'Vallo', 'T. Vent', 'Flégère', 'Cham', 'Year']\n",
      "2011 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delevre', 'st Ger', 'Conta', 'Balme', 'Bonhom', 'Chapieu', 'Seigne', 'Combal', 'M Favre', 'Checrou', 'Courm', 'Bertone', 'Bonatti', 'Arnuva', 'Ferret', 'Fouly', 'Champex', 'Martign', 'Trient', 'Catogne', 'Vallo', 'Argent', 'Cham', 'Year']\n",
      "2012 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delev', 'StGer', 'Conta', 'Balme', 'conta r', 'bellevu', 'houches', 'gare pp', 'argenti', '-1km', 'arrivee', 'Year']\n",
      "2013 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delev', 'StGer', 'Conta', 'Balme', 'Bonhom', 'Chapieu', 'Seigne', 'Combal', 'MtFavre', 'Checrou', 'Courm', 'Bertone', 'Bonatti', 'Arnuva', 'GdColF', 'Fouly', 'Champex', 'Bovine', 'Trient', 'Catogne', 'Vallo', 'TaVents', 'Flégère', 'Arrivé', 'Year']\n",
      "2014 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delev', 'StGer', 'Conta', 'Balme', 'Bonhom', 'Chapieu', 'Seigne', 'Combal', 'MtFavre', 'Checrou', 'Courm', 'Bertone', 'Bonatti', 'Arnuva', 'GdColF', 'Fouly', 'Champex', 'Giète', 'Trient', 'Catogne', 'Vallo', 'TaVents', 'Flégère', 'Arrivée', 'Year']\n",
      "2015 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delev', 'StGer', 'Conta', 'Balme', 'Bonhom', 'Chapieu', 'Seigne', 'Combal', 'MtFavre', 'Checrou', 'Courm1', 'Courm2', 'Bertone', 'Bonatti', 'Arnuva', 'GdColF', 'Fouly', 'Champex', 'Giete', 'Trient', 'Catogne', 'Vallo', 'TaVents', 'Flegere', 'Arrivee', 'Year']\n",
      "2016 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delevret', 'St Gervais', 'Contamines', 'Balme', 'Bonhomme', 'Chapieu', 'Seigne', 'Combal', 'MtFavre', 'Checrou', 'Courm1', 'Courm2', 'Villaz', 'Bertone', 'Bonatti', 'Arnuva', 'GdColF', 'Fouly', 'Champex', 'Giete', 'Trient', 'Catogne', 'Vallo', 'TaVents', 'Flegere', 'Arrivee', 'Year']\n",
      "2017 ['Unnamed: 0', 'bib', 'name', 'team', 'category', 'rank', 'nationality', 'time', 'timediff', 'Delevret', 'St-Gervais', 'Contamines', 'La Balme', 'Bonhomme', 'Chapieux', 'Col Seigne', 'Lac Combal', 'Mt-Favre', 'Checruit', 'Courmayeur', 'Bertone', 'Bonatti', 'Arnouvaz', 'Col Ferret', 'La Fouly', 'Champex La', 'La Giète', 'Trient', 'Les Tseppe', 'Vallorcine', 'Col Montet', 'Flégère', 'Arrivée', 'Year']\n"
     ]
    }
   ],
   "source": [
    "# función auxiliar para cargar csv. Si nrows es menor que 0 devuelve todas las filas\n",
    "\n",
    "\n",
    "def read_csvs(nrows, show=True):\n",
    "    dic = dict()\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        year = file[5:9]\n",
    "        if nrows > 0:\n",
    "            args = {'filepath_or_buffer': full_file(\n",
    "                raw_folder, file), 'nrows': nrows}\n",
    "        else:\n",
    "            args = args = {'filepath_or_buffer': full_file(raw_folder, file)}\n",
    "        dic[year] = pd.read_csv(**args)\n",
    "        dfd = dic[year]\n",
    "        dfd['Year'] = year\n",
    "        if show:\n",
    "            # muestra el nombre del fichero y sus columnas\n",
    "            print(year, list(dfd))\n",
    "        df = pd.concat([df, dfd], sort=False)\n",
    "    return dic, df\n",
    "\n",
    "\n",
    "df_dict, df = read_csvs(nrows=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Vemos que en el número y nombre de columnas de cada dataframe es bastante variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 136)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### En el dataframe global tenemos ¡136! columnas cuyos nombres se listan abajo, hay que tener en cuenta que las que tienen el mismo nombre en los ficheros de origen solo se ven una vez, nos espera un arduo trabajo... Comienzo por listar las columnas ordenadas alfabéticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1km', 'Argent', 'Argentière', 'Arnouvaz', 'Arnuva', 'Arrivee',\n",
       "       'Arrivé', 'Arrivée', 'Arête Mont-Favre', 'Balme', 'Berton',\n",
       "       'Bertone', 'Bonatti', 'Bonhom', 'Bonhomme', 'Bovine', 'Catogn',\n",
       "       'Catogne', 'Cham', 'Chamonix - Arrivée', 'Champ', 'Champex',\n",
       "       'Champex La', 'Champex Lac', \"Champex d'en Bas\", 'Chap', 'Chapieu',\n",
       "       'Chapieux', 'Charme', 'Checr', 'Checrou', 'Checruit',\n",
       "       'Col Chécrouit - Maison Vieille', 'Col Ferret', 'Col Montet',\n",
       "       'Col Seigne', 'Col de Voza', 'Col de la Seigne', 'ColFerr',\n",
       "       'Combal', 'Conta', 'Contamines', 'Courm', 'Courm1', 'Courm2',\n",
       "       'Courmayeur', 'Courmayeur - Dolonne', 'Delev', 'Delevre',\n",
       "       'Delevret', 'Elena', 'Favre', 'Ferret', 'Fleg', 'Flegere',\n",
       "       'Flégère', 'Fouly', 'Gardes', 'GdColF', 'Giete', 'Giète',\n",
       "       'Grand Col Ferret', 'La Balme', 'La Charme', 'La Fouly',\n",
       "       'La Giète', 'La Peulaz', 'Lac Combal', 'Les Chapieux CCAS',\n",
       "       'Les Contamines', 'Les Tseppe', 'Les Tseppes', 'M Favre',\n",
       "       'Martign', 'Mt-Favre', 'MtFavre', 'Praz de Fort', 'Refuge Bertone',\n",
       "       'Refuge Bonatti', 'Refuge Croix du Bonhomme', 'Refuge Elisabetta',\n",
       "       'Saint-Gervais', 'Seigne', 'St Gervais', 'St-Gervais', 'StGer',\n",
       "       'T. Vent', 'TaVents', 'TeteVnt', 'Trient', 'Unnamed: 0', 'Vallo',\n",
       "       'Vallor', 'Vallorc', 'Vallorcine', 'Villaz', 'Voza', 'Year',\n",
       "       'argenti', 'arnuv', 'arrivee', 'balme', 'bellevu', 'bert', 'bib',\n",
       "       'bonat', 'bovine', 'category', 'catog', 'cham', 'champ', 'chap',\n",
       "       'checr', 'combal', 'conta', 'conta r', 'courm', 'crxBon', 'ferret',\n",
       "       'fleg', 'fouly', 'gare pp', 'houches', 'mtFav', 'name',\n",
       "       'nationality', 'rank', 'seign', 'st Ger', 'stGer', 'team',\n",
       "       'teteVnt', 'time', 'timediff', 'trient', 'vallo'], dtype='<U30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = np.array(list(df))\n",
    "columns.sort()\n",
    "columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Se observan básicamente dos cosas:\n",
    " 1. Algunas de ellas están repetidas, pero cambia la capitalización de las letras: ```'Champ' – 'champ'```.\n",
    " 2. Muchas de ellas se parecen ej.: ```'Champex La', 'Champex Lac'```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Pasamos todos los nombres de columnas a minúsculas y recuperamos los valores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1km', 'argent', 'argenti', 'argentière', 'arnouvaz', 'arnuv',\n",
       "       'arnuva', 'arrivee', 'arrivé', 'arrivée', 'arête mont-favre',\n",
       "       'balme', 'bellevu', 'bert', 'berton', 'bertone', 'bib', 'bonat',\n",
       "       'bonatti', 'bonhom', 'bonhomme', 'bovine', 'category', 'catog',\n",
       "       'catogn', 'catogne', 'cham', 'chamonix - arrivée', 'champ',\n",
       "       'champex', \"champex d'en bas\", 'champex la', 'champex lac', 'chap',\n",
       "       'chapieu', 'chapieux', 'charme', 'checr', 'checrou', 'checruit',\n",
       "       'col chécrouit - maison vieille', 'col de la seigne',\n",
       "       'col de voza', 'col ferret', 'col montet', 'col seigne', 'colferr',\n",
       "       'combal', 'conta', 'conta r', 'contamines', 'courm', 'courm1',\n",
       "       'courm2', 'courmayeur', 'courmayeur - dolonne', 'crxbon', 'delev',\n",
       "       'delevre', 'delevret', 'elena', 'favre', 'ferret', 'fleg',\n",
       "       'flegere', 'flégère', 'fouly', 'gardes', 'gare pp', 'gdcolf',\n",
       "       'giete', 'giète', 'grand col ferret', 'houches', 'la balme',\n",
       "       'la charme', 'la fouly', 'la giète', 'la peulaz', 'lac combal',\n",
       "       'les chapieux ccas', 'les contamines', 'les tseppe', 'les tseppes',\n",
       "       'm favre', 'martign', 'mt-favre', 'mtfav', 'mtfavre', 'name',\n",
       "       'nationality', 'praz de fort', 'rank', 'refuge bertone',\n",
       "       'refuge bonatti', 'refuge croix du bonhomme', 'refuge elisabetta',\n",
       "       'saint-gervais', 'seign', 'seigne', 'st ger', 'st gervais',\n",
       "       'st-gervais', 'stger', 't. vent', 'tavents', 'team', 'tetevnt',\n",
       "       'time', 'timediff', 'trient', 'unnamed: 0', 'vallo', 'vallor',\n",
       "       'vallorc', 'vallorcine', 'villaz', 'voza', 'year'], dtype='<U30')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = np.char.lower(np.array(list(df)))\n",
    "columns = np.lib.arraysetops.unique(columns)\n",
    "columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Verificamos que hemos conseguido reducir el número de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Vamos a dar un primer vistazo al contenido del dataframe global para ver qué datos almacena. Se muestran 10 observaciones al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opción para mostrar todas las columnas del dataframe\n",
    "pd.set_option('display.max_columns', df.shape[1])\n",
    "# elegimos 10 al azar\n",
    "# todo uncomment\n",
    "# df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### La mayoría de ellas son tiempos de paso y sus nombres, con seguridad, el lugar dónde se ha cronometrado al corredor. También hay otros datos como dorsal, nombre, equipo, categoría, posición y similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Para continuar, se ha de mapear cada columna con un nuevo nombre que agrupe a sus “parecidos razonables” en una relación n a 1. Por ejemplo, es lógico relacionar ```'bert', 'berton', 'bertone'``` con ```'Bertone'```. Para esta tarea se ha de identificar cada nombre con algún lugar atravesado por el recorrido. *Behind the scenes*, usando la web de la carrera, Google Maps y algo de paciencia, se ha montado una tabla con las relaciones. De todas ellas, no ha sido posible identificar cinco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Para distinguir las columnas de tiempos, las desconocidas y las restantes, se añade un campo calificador. Se han hecho dos iteraciones en este proceso ya que en la concatenación final de dataframes fallaban el año 2012 –tiene dos campos ```'conta'``` y ```'conta r'``` que se asignaban a ```'Contamines'```– y el año 2015 – tiene dos campos ```'courm1'``` y ```'courm2'``` que se asignaban a ```'Courmayeur'```–."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Igualmente se ha añadido un campo de conveniencia ```Order``` por el cual se ordenarán las columnas del dataframe final. Todas las columnas de tiempo están situadas al final del dataframe a partir del índice 8 y su posición es relativa al recorrido de la carrera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En el dataframe hay dos campos: ```'Cham', 'cham'``` que pueden ser Champex o Chamoniz, en el listado del dataframe más arriba se verifica que sus tiempos son superiores a los de paso por Champex y similares a los de la llegada a Chamonix. Se asignan pues a este último y el nombre del campo será ```Arrivee``` respetando el original francés para llegada pero sin signos de acentuación, para el resto de los campos se han eliminado igualmente, así como los espacios y guiones manteniendo únicamente los caracteres del alfabeto inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### El resultado del trabajo descrito se guarda en un fichero csv que se recupera en la celda inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>type</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1km</td>\n",
       "      <td>1km</td>\n",
       "      <td>Crono</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argent</td>\n",
       "      <td>Argentiere</td>\n",
       "      <td>Crono</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>argenti</td>\n",
       "      <td>Argentiere</td>\n",
       "      <td>Crono</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arnouvaz</td>\n",
       "      <td>Arnouvaz</td>\n",
       "      <td>Crono</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arnuv</td>\n",
       "      <td>Arnouvaz</td>\n",
       "      <td>Crono</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arnuva</td>\n",
       "      <td>Arnouvaz</td>\n",
       "      <td>Crono</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arrivee</td>\n",
       "      <td>Arrivee</td>\n",
       "      <td>Crono</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arrivé</td>\n",
       "      <td>Arrivee</td>\n",
       "      <td>Crono</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arrivée</td>\n",
       "      <td>Arrivee</td>\n",
       "      <td>Crono</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chamonix - arrivée</td>\n",
       "      <td>Arrivee</td>\n",
       "      <td>Crono</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cham</td>\n",
       "      <td>Arrivee</td>\n",
       "      <td>Crono</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert</td>\n",
       "      <td>Bertone</td>\n",
       "      <td>Crono</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bellevu</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>Crono</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>berton</td>\n",
       "      <td>Bertone</td>\n",
       "      <td>Crono</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bertone</td>\n",
       "      <td>Bertone</td>\n",
       "      <td>Crono</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   old         new   type  order\n",
       "0                 -1km         1km  Crono    141\n",
       "1               argent  Argentiere  Crono    139\n",
       "2              argenti  Argentiere  Crono    139\n",
       "3             arnouvaz    Arnouvaz  Crono    123\n",
       "4                arnuv    Arnouvaz  Crono    123\n",
       "5               arnuva    Arnouvaz  Crono    123\n",
       "6              arrivee     Arrivee  Crono    142\n",
       "7               arrivé     Arrivee  Crono    142\n",
       "8              arrivée     Arrivee  Crono    142\n",
       "9   chamonix - arrivée     Arrivee  Crono    142\n",
       "10                cham     Arrivee  Crono    142\n",
       "11                bert     Bertone  Crono    120\n",
       "12             bellevu    Bellevue  Crono    107\n",
       "13              berton     Bertone  Crono    120\n",
       "14             bertone     Bertone  Crono    120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'columns.csv'\n",
    "data_folder = 'data'\n",
    "cols_map = pd.read_csv(full_file(data_folder, file))\n",
    "cols_map[:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Las variables desconocidas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>type</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>conta r</td>\n",
       "      <td>ContaR</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>courm2</td>\n",
       "      <td>Courmayeur2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>gardes</td>\n",
       "      <td>Gardes</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>gare pp</td>\n",
       "      <td>GarePp</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>villaz</td>\n",
       "      <td>Villaz</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         old          new     type  order\n",
       "55   conta r       ContaR  Unknown    106\n",
       "64    courm2  Courmayeur2  Unknown    118\n",
       "67    gardes       Gardes  Unknown    140\n",
       "68   gare pp       GarePp  Unknown    109\n",
       "116   villaz       Villaz  Unknown    119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknowns = cols_map.loc[cols_map['type'] == 'Unknown']\n",
    "unknowns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Para continuar, esta vez cargaremos todos los datos sin mostrarlos por pantalla usando la función auxiliar creada en la celda 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict, df = read_csvs(nrows=-1, show=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Ahora hay que renombrar las columnas de cada dataframe. Es importante tener en cuenta que esta parte se ha de realizar en cada dataframe individual, para después concatenarlos; si se hiciera en el dataframe global, los nuevos nombres de las columnas con diferente capitalización devendrían idénticos. Se inicializa el dataframe global en el cual se concatenan todos los dataframes anuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 53)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inicializamos el dataframe global\n",
    "df = pd.DataFrame()\n",
    "# recorremos el diccionario\n",
    "for k, dfd in df_dict.items():\n",
    "    # creamos un dataframe de una columna con el nombre de las columnas en minúsculas\n",
    "    cols_dfd = pd.DataFrame(np.char.lower(np.array(list(dfd))))\n",
    "    # le ponemos el mismo nombre que tiene su columna equivalente en el mapa\n",
    "    cols_dfd.columns = ['old']\n",
    "    # hacemos un merge del mapa y las columnas originales por 'old'\n",
    "    cols_new = pd.merge(cols_dfd, cols_map)['new'].tolist()\n",
    "    # cambiamos el nombre de las columnas en el original\n",
    "    dfd.columns = cols_new\n",
    "    # añadimos el dataframe anual corregido al dataframe global\n",
    "    df = pd.concat([df, dfd], sort=False)\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Comprobamos sus dimensiones y vemos que las variables han pasado de 136 a 53. No está mal…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Ordenamos las columnas según el mapa de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order se repite en las nuevas columnas que agrupan las originales\n",
    "# se coge el valor mínimo, pero valdría igual el máximo o la media\n",
    "group = cols_map.groupby('new')['order'].min().sort_values()\n",
    "# guardamos la columnas ordenadas\n",
    "columns_order = list(group.index.values)\n",
    "# se reindexa el dataframe global con las columnas ordenadas\n",
    "df = df.reindex(columns=columns_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Ahora revisamos si hay variables con todas las observaciones nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Villaz']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empties = df.columns[df.isna().all()].tolist()\n",
    "empties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Aparece una y la eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 52)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=empties, inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Los datos de las columnas tipo crono son ```timedeltas```. Vamos a asegurarnos de que todos están correctamente formados antes de acabar la limpieza.\n",
    " #### Si miramos los datos de ```Timediff``` vemos que hay observaciones con la forma ```mm:ss.0``` y la función espera ```hh:mm:ss.0```. Vamos a pasar esos datos al formato ```hh:mm:ss```, también válido para ```pd.to_timedelta()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    00:00.0\n",
       "1    09:19.0\n",
       "2    09:19.0\n",
       "3    31:19.0\n",
       "4    12:38.0\n",
       "Name: Timediff, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Timediff'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    00:00:00\n",
       "1    00:09:19\n",
       "2    00:09:19\n",
       "3    00:31:19\n",
       "4    00:12:38\n",
       "Name: Timediff, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reseteamos el índice ya que vamos a utilizar máscaras para actuar solamente\n",
    "# sobre las observaciones afectadas\n",
    "df = df.reset_index(drop=True)\n",
    "# creamos una máscara con los valores que acaban en .0 ignorando los no nulos\n",
    "mask = df['Timediff'].str.endswith(\".0\") & pd.notnull(df['Timediff'])\n",
    "# se hace el reemplazamiento usando sintaxis regex\n",
    "df['Timediff'] = df['Timediff'].loc[mask].str.replace('\\\\.0', '', 1)\n",
    "# se añade la parte hh: al principio\n",
    "df['Timediff'] = df['Timediff'].loc[mask].apply(lambda x: '00:' + x)\n",
    "df['Timediff'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Verificamos que todos los valores aceptan la conversión a timedelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "Timediff\n",
      "ColDeVoza\n",
      "LaCharme\n",
      "Delevret\n",
      "StGervais\n",
      "Contamines\n",
      "LaBalme\n",
      "ContaR\n",
      "Bellevue\n",
      "LesHouches\n",
      "GarePp\n",
      "Bonhomme\n",
      "Chapieux\n",
      "ColSeigne\n",
      "RefugeElisabetta\n",
      "LacCombal\n",
      "MtFavre\n",
      "Checrouit\n",
      "Courmayeur\n",
      "Courmayeur2\n",
      "Bertone\n",
      "RifugioElena\n",
      "Bonatti\n",
      "Arnouvaz\n",
      "ColFerret\n",
      "LaPeule\n",
      "LaFouly\n",
      "PrazDeFort\n",
      "Champex\n",
      "Martigny\n",
      "Bovinette\n",
      "LaGiete\n",
      "Trient\n",
      "Tseppes\n",
      "Catogne\n",
      "Vallorcine\n",
      "ColDesMontets\n",
      "LaTeteAuxVents\n",
      "LaFlegere\n",
      "Argentiere\n",
      "Gardes\n",
      "1km\n",
      "Arrivee\n"
     ]
    }
   ],
   "source": [
    "cronos_list = list(df)[8:]\n",
    "cronos_df = df[df.columns.intersection(cronos_list)]\n",
    "for crono in cronos_list:\n",
    "    print(crono)\n",
    "    pd.to_timedelta(cronos_df[crono])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **¡Prueba superada! ;-)** Con este paso acaba esta parte del trabajo, guardamos el resultado del dataframe final en un fichero csv que se recuperará en la parte de exploración de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'utmb.1.csv'\n",
    "df.to_csv(full_file(data_folder, file), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
